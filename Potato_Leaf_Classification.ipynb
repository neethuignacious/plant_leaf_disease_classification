{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models,layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 256\n",
    "BATCH_SIZE = 32\n",
    "CHANNELS = 3\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1506 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "                rescale=1./255,\n",
    "                horizontal_flip=True,\n",
    "                zoom_range=0.3,\n",
    "                shear_range = 0.2    \n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'potatodata/train',\n",
    "        target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 215 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_datagen = ImageDataGenerator(\n",
    "                rescale=1./255,\n",
    "                horizontal_flip=True,\n",
    "                zoom_range=0.3,\n",
    "                shear_range = 0.2   \n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        'potatodata/val',\n",
    "        target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 431 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "                rescale=1./255,\n",
    "  \n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'potatodata/test',\n",
    "        target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n",
    "n_classes = 3\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.InputLayer(input_shape=input_shape),\n",
    "    layers.Conv2D(32, kernel_size = (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(n_classes, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "48/48 [==============================] - 177s 4s/step - loss: 0.9394 - accuracy: 0.4835 - val_loss: 0.8613 - val_accuracy: 0.4791\n",
      "Epoch 2/20\n",
      "48/48 [==============================] - 178s 4s/step - loss: 0.7968 - accuracy: 0.5970 - val_loss: 0.5168 - val_accuracy: 0.7860\n",
      "Epoch 3/20\n",
      "48/48 [==============================] - 173s 4s/step - loss: 0.5364 - accuracy: 0.7645 - val_loss: 0.5351 - val_accuracy: 0.7349\n",
      "Epoch 4/20\n",
      "48/48 [==============================] - 176s 4s/step - loss: 0.4029 - accuracy: 0.8145 - val_loss: 0.4788 - val_accuracy: 0.7674\n",
      "Epoch 5/20\n",
      "48/48 [==============================] - 184s 4s/step - loss: 0.4007 - accuracy: 0.8191 - val_loss: 0.4071 - val_accuracy: 0.8744\n",
      "Epoch 6/20\n",
      "48/48 [==============================] - 167s 3s/step - loss: 0.3778 - accuracy: 0.8533 - val_loss: 0.3497 - val_accuracy: 0.8372\n",
      "Epoch 7/20\n",
      "48/48 [==============================] - 169s 4s/step - loss: 0.2877 - accuracy: 0.8869 - val_loss: 0.5982 - val_accuracy: 0.7163\n",
      "Epoch 8/20\n",
      "48/48 [==============================] - 170s 4s/step - loss: 0.4170 - accuracy: 0.8186 - val_loss: 0.3036 - val_accuracy: 0.8791\n",
      "Epoch 9/20\n",
      "48/48 [==============================] - 171s 4s/step - loss: 0.2714 - accuracy: 0.8950 - val_loss: 0.3345 - val_accuracy: 0.8465\n",
      "Epoch 10/20\n",
      "48/48 [==============================] - 215s 4s/step - loss: 0.2762 - accuracy: 0.8929 - val_loss: 0.1946 - val_accuracy: 0.9116\n",
      "Epoch 11/20\n",
      "48/48 [==============================] - 247s 5s/step - loss: 0.1757 - accuracy: 0.9290 - val_loss: 0.1816 - val_accuracy: 0.9163\n",
      "Epoch 12/20\n",
      "48/48 [==============================] - 190s 4s/step - loss: 0.1912 - accuracy: 0.9219 - val_loss: 0.1698 - val_accuracy: 0.9349\n",
      "Epoch 13/20\n",
      "48/48 [==============================] - 269s 6s/step - loss: 0.1866 - accuracy: 0.9343 - val_loss: 0.1193 - val_accuracy: 0.9488\n",
      "Epoch 14/20\n",
      "48/48 [==============================] - 196s 4s/step - loss: 0.1009 - accuracy: 0.9610 - val_loss: 0.1274 - val_accuracy: 0.9488\n",
      "Epoch 15/20\n",
      "48/48 [==============================] - 195s 4s/step - loss: 0.1147 - accuracy: 0.9477 - val_loss: 0.2486 - val_accuracy: 0.8791\n",
      "Epoch 16/20\n",
      "48/48 [==============================] - 210s 4s/step - loss: 0.1307 - accuracy: 0.9493 - val_loss: 0.0611 - val_accuracy: 0.9674\n",
      "Epoch 17/20\n",
      "48/48 [==============================] - 222s 5s/step - loss: 0.0590 - accuracy: 0.9793 - val_loss: 0.0729 - val_accuracy: 0.9674\n",
      "Epoch 18/20\n",
      "48/48 [==============================] - 219s 5s/step - loss: 0.0449 - accuracy: 0.9800 - val_loss: 0.0824 - val_accuracy: 0.9581\n",
      "Epoch 19/20\n",
      "48/48 [==============================] - 238s 5s/step - loss: 0.0580 - accuracy: 0.9800 - val_loss: 0.0996 - val_accuracy: 0.9535\n",
      "Epoch 20/20\n",
      "48/48 [==============================] - 188s 4s/step - loss: 0.2079 - accuracy: 0.9240 - val_loss: 0.4624 - val_accuracy: 0.8140\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    batch_size=32,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator),\n",
    "    epochs=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"potato_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
